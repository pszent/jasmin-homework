{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the dependencies and set the device to cuda to speed up inference if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from app.resnet_embedding import Resnet50emb\n",
    "\n",
    "from app.dataset import CustomDataset\n",
    "\n",
    "with open('class_indexes.json', 'r') as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the validation dataset into a custom dataset class (which does the preprocessing as well - see the relevant [notebook](/home/jovyan/notebooks/dataloader.ipynb)).\n",
    "\n",
    "setting the data loader batch size to 32 and the number of workers to 4. inference can be sped up by lowering the batch size or increasing the number of workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = CustomDataset('../data/')\n",
    "dataloader = DataLoader(dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use my custom model built on Resnet50 which does the embedding. Setting the model to cuda too if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet50emb()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "switch to eval mode (as we're using a pre-trained model for validation and not for training), then we do an inference on each batch.\n",
    "First make a softmax on the embedded output, get the mean and variance, all flattened to 1D numpy arrays, so I can print out the relevant values easily.\n",
    "\n",
    "Then I get the 2 most probable predictions and print out the prediction labels and the corresponding probability in a 2 digit fraction percentage format so the outputs are kept readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to eval so inference is quicker\n",
    "model.eval()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for batch in dataloader:\n",
    "    batch = batch.to(device, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "        embedding, output = model(batch)\n",
    "\n",
    "    softmaxed = torch.softmax(embedding, dim=1)\n",
    "\n",
    "    # get means and variances - could be done with the torch.var_mean() too but this is more readable\n",
    "    mean = torch.mean(embedding, dim=1).cpu().numpy()\n",
    "    variance = torch.var(embedding, dim=1).cpu().numpy()\n",
    "\n",
    "    for index, value in enumerate(mean):\n",
    "        print(f'mean: {value} variance: {variance[index]} of image #{index + 1}')\n",
    "    print('----------')\n",
    "\n",
    "    # get the 2 most probable prediction\n",
    "    top2 = torch.topk(softmaxed, 2, dim=1)\n",
    "    probabilities = top2[0].cpu().numpy()\n",
    "    indices = top2[1].cpu().numpy()\n",
    "\n",
    "    for index, value in enumerate(indices):\n",
    "        print(\n",
    "            f'image #{index+1} is {probabilities[index][0] * 100:.2f}% a {labels[str(value[0])]} and '\n",
    "            f'{probabilities[index][1] * 100:.2f}% a {labels[str(value[1])]}')\n",
    "\n",
    "    print(f'inference in python took {time.time()-start:.2f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
